# ğŸ¹ Gesture-Controlled Virtual Instrument

A real-time gesture-based MIDI instrument using your webcam and hand gestures. Built with Python, OpenCV, MediaPipe, and FluidSynth.

---

## âœ¨ Features

- Real-time hand tracking using MediaPipe  
- Two-hand gesture input for dual instrument control  
- Gesture-to-chord mapping (Open Palm, 1â€“4 Fingers, Fist)  
- Play any General MIDI instrument via `.sf2` SoundFont  
- Lightweight UI for selecting left and right hand instruments  
- Modular codebase for extensibility

---

## ğŸš€ Installation

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/gesture_instrument.git
cd gesture_instrument
```

### 2. Create a virtual environment

```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

Or manually:

```bash
pip install opencv-python mediapipe pyfluidsynth
```

---

## ğŸµ SoundFont Setup

This project requires a `.sf2` SoundFont file for instrument playback.

We recommend **FluidR3_GM.sf2** (~148 MB):

### âœ… Option 1: Download manually

Download from:  
https://member.keymusician.com/Member/FluidR3_GM/

Then place the file at:

```text
gesture_instrument/assets/FluidR3_GM/FluidR3_GM.sf2
```

**Important:**  
> Do **not** commit this file to GitHub. It's over 100MB and will break GitHub pushes.  
> Add it to `.gitignore`.

---

## ğŸ–¥ï¸ Running the App

### 1. Start the UI to select instruments

```bash
cd gesture_ui
python manage.py runserver
```

Go to http://127.0.0.1:8000 and choose instruments for left/right hands.

### 2. Run the gesture instrument

In a new terminal tab:

```bash
python main.py
```

---

## ğŸ§ª Testing Without UI

You can run the system directly by editing `instrument_selection.json`.

```json
{
  "left_instrument": 0,
  "right_instrument": 24
}
```

Use [General MIDI Instrument Numbers](https://www.midi.org/specifications-old/item/gm-level-1-sound-set) as reference.

---

## ğŸ› ï¸ Troubleshooting

### âŒ No sound?

- Make sure your `.sf2` path is correct  
- Use `coreaudio` (Mac), `alsa` (Linux), or `dsound` (Windows) for FluidSynth  
- Try using headphones or unmuting system audio

### ğŸ™ƒ Gestures flipped?

- Flip camera feed or adjust handedness logic in `main.py`
- Look for `cv2.flip()` or `label == 'Right'` logic

---

## ğŸ“ Project Structure

```text
gesture_instrument/
â”œâ”€â”€ main.py
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ FluidR3_GM/
â”‚       â””â”€â”€ FluidR3_GM.sf2
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ gesture_detector.py
â”‚   â”œâ”€â”€ hand_tracker.py
â”‚   â””â”€â”€ sound_engine.py
â”œâ”€â”€ gesture_ui/
â”‚   â”œâ”€â”€ manage.py
â”‚   â”œâ”€â”€ gesture_ui/
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”‚   â””â”€â”€ wsgi.py
â”‚   â””â”€â”€ selector/
â”‚       â”œâ”€â”€ templates/
â”‚       â”œâ”€â”€ views.py
â”‚       â””â”€â”€ forms.py
â””â”€â”€ instrument_selection.json
```

---

## ğŸ™ Credits

- [MediaPipe](https://github.com/google/mediapipe)  
- [FluidSynth](https://www.fluidsynth.org/)  
- [OpenCV](https://opencv.org/)

